<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>oneDNN Wrapper: oneDNN Wrapper</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="doxygen-awesome.css" rel="stylesheet" type="text/css"/>
<link href="doxygen-awesome-sidebar-only.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">oneDNN Wrapper
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('index.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">oneDNN Wrapper </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="md_README"></a></p>
<p>oneDNN wrapper is a project written in C++ which "wraps" oneDNN primitive into simpler and more usable classes, in order to implement Deep Neural Networks in a way that is more similar to TensorFlow or Pytorch.</p>
<h1><a class="anchor" id="autotoc_md0"></a>
Getting Started</h1>
<p>The following tutorial will show the basic building blocks to build a fully connected network. A full working example based on the skin segmentation dataset (<a href="https://archive.ics.uci.edu/ml/datasets/skin+segmentation">https://archive.ics.uci.edu/ml/datasets/skin+segmentation</a>) is available in onednn_training_skin.cpp .</p>
<p>First we need to allocate all the required memory spaces for our model. In the example we consider a simple fully connected network with two layers, one with 5 hidden neurons and one with a single output neuron. To train any network we need to prepare three different pipelines:</p><ul>
<li>A forward pipeline, which simply provides inference (ie. the forward pass)</li>
<li>A backward data pipeline, which computes the gradient of each input of the network with respect to the loss</li>
<li>A backward weights pipeline, which starting from the gradient of the input and the output computes the gradient of the weights with respect to the loss</li>
<li>An update weights pipeline, which performs Gradient Descent on the weights</li>
</ul>
<h2><a class="anchor" id="autotoc_md1"></a>
Creating a pipeline</h2>
<p>To create a primitives pipeline we use the procedure described in the example onednn_training_skin.cpp, and in the oneDNN documentation. It is sufficient to allocate a vector of dnnl::primitive and a memory map </p><pre class="fragment">std::vector&lt;dnnl::primitive&gt; net_fwd
std::vector&lt;std::unordered_map&lt;int, memory&gt;&gt; net_fwd_args
</pre><p> The dnnl:: suffix can be omitted when we are in the dnnl namespace.</p>
<h3><a class="anchor" id="autotoc_md2"></a>
Forward Pass</h3>
<p>To create a primitive you instantiate a class. For every class the procedure is quite similar, you simply have to include different arguments depending on the primitive you are using. In this example we will explain how to create a primitive for a dense layer; all the information regarding the other primitives is available in the specific pages.</p>
<p>In a fully connected layer we will have to allocate:</p>
<ul>
<li>The weights 2D vector of size {OUTPUT, INPUT}, since we will have to do the dot product wT x</li>
<li>The bias vector of size {OUTPUT}</li>
<li>The output 2D vector of size {BATCH, OUTPUT}</li>
</ul>
<p>This is done automatically by the wrapper and it is sufficient to create a class of type <a class="el" href="classDense.html" title="Dense allows to create a fully connected layer forward primitive.">Dense</a> with the proper arguments. </p><pre class="fragment">Dense fc1(fc1_output_size, input_memory, net_fwd, net_fwd_args, eng);
</pre><p> Let's unpack this line a bit:</p><ul>
<li>fc1_src_dims provides the input dimensions as a dnnl::memory::dims vector</li>
<li>fc1_output_size provides the output dimensions as a dnnl::memory::dims vector</li>
<li>input_memory provides the dnnl::memory object containing the input</li>
<li>net_fwd is the vector of dnnl::primitives which contain the full pipeline. The <a class="el" href="classDense.html#ac84196f789601c3d5aea1a0022c4c29f" title="Construct a new Dense object.">Dense::Dense</a> class constructor will automatically append the correct primitive when instantiated</li>
<li>net_fwd_args is the unordered map which provides the arguments for each primitives, again this is done automatically by the wrapper</li>
<li>eng is the dnnl::engine that we are using</li>
</ul>
<h3><a class="anchor" id="autotoc_md3"></a>
Backward Data Pass</h3>
<p>In a similar fashion to the Forward Pass we create the backward pass for the <a class="el" href="classDense.html" title="Dense allows to create a fully connected layer forward primitive.">Dense</a> layer: </p><pre class="fragment">Dense_back_data fc1_back_data(relu1_back_data.arg_diff_src, fc1, net_bwd_data, net_bwd_data_args, eng);
</pre><p> Here we have:</p>
<ul>
<li>relu1_back_data.arg_diff_src which is the input argument ie. the gradient of the source with respect to the loss</li>
<li>fc1 which is the original class containing the forward primitive</li>
<li>net_bwd_data which is the vector of dnnl::primitives relative to the backward data pipeline</li>
<li>net_bwd_data_args which is the memory map associated to net_bwd_data</li>
<li>eng is the dnnl::engine that we are using</li>
</ul>
<h3><a class="anchor" id="autotoc_md4"></a>
Backward Weights Pass</h3>
<p>Last but not least we have our backward weights pass. Here we will use all the gradients computed in the backward data pipeline to compute the gradients with respect to the weights. Again, considering the <a class="el" href="classDense.html" title="Dense allows to create a fully connected layer forward primitive.">Dense</a> layer we instantiate the backward weights pass as follows: </p><pre class="fragment">Dense_back_weights fc1_back_weights(relu1_back_data.arg_diff_src, fc1, net_bwd_weights, net_bwd_weights_args, eng);
</pre><ul>
<li>relu1_back_data.arg_diff_src which is the input argument ie. the gradient of the source with respect to the loss</li>
<li>fc1 which is the original class containing the forward primitive</li>
<li>net_bwd_weights which is the vector of dnnl::primitives relative to the backward weights pipeline</li>
<li>net_bwd_weights_args which is the memory map associated to net_bwd_data</li>
<li>eng is the dnnl::engine that we are net_bwd_weights</li>
</ul>
<h2><a class="anchor" id="autotoc_md5"></a>
Data Loading</h2>
<p>Data is loaded inside the oneAPI memory using the <a class="el" href="classDataLoader.html" title="DataLoader allows to create a dataloader object to implement minibatch stochastic gradient descent.">DataLoader</a> class. It reads the file in flattended txt format, which means that the vectors are written in row-major order in a text file. An example on how to generate these files starting from a csv is available in dataset_utils.</p>
<p>To instantiate a data loader the syntax is the following <a class="el" href="classDataLoader.html" title="DataLoader allows to create a dataloader object to implement minibatch stochastic gradient descent.">DataLoader</a> skin_data(dataset_path, labels_path, batch, dataset_shape, eng);</p>
<ul>
<li>dataset_path is the path to the file containing the features</li>
<li>labels_path is the path to the file containing the labels</li>
<li>batch is the minibatch size</li>
<li>dataset_shape is the shape of each feature, for example it can be a vector of the form {N, C, H} for an image or {C} for a simple feature vector that has length C</li>
<li>eng is the oneAPI engine</li>
</ul>
<p>Once the data loader class is instantiated we can simply use </p><pre class="fragment">skin_data.write_to_memory(input_memory, labels_memory)
</pre><p> to load a batch of features and label inside the dnnl::memory objects: input_memory and labels_memory. The useful thing about this method is that it can be called as many times as we need, everytime we need a new mini-batch.</p>
<h3><a class="anchor" id="autotoc_md6"></a>
Inference</h3>
<p>To have inference we can instantiate an extra dataloader with a validation set. To have batch size as large as the sample size we can put -1. </p><pre class="fragment">DataLoader skin_data(dataset_path, labels_path, -1, dataset_shape, eng)
</pre> </div></div><!-- PageDoc -->
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1 </li>
  </ul>
</div>
</body>
</html>
