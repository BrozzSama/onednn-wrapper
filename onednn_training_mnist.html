<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>oneDNN Wrapper: CNN example using oneDNN wrapper</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">oneDNN Wrapper
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('onednn_training_mnist.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">CNN example using oneDNN wrapper </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>This C++ example demonstrates how to build a simple CNN model made of a Convolutional Layer, Maxpooling layer and a Fully connected layer with one output</p>
<div class="fragment"><div class="line"> </div>
<div class="line"><span class="preprocessor">#include &lt;cassert&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;cmath&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;iostream&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;stdexcept&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;random&gt;</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#include &quot;oneapi/dnnl/dnnl.hpp&quot;</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#include &quot;intel_utils.h&quot;</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#include &quot;misc/include/npy.hpp&quot;</span></div>
<div class="line"><span class="preprocessor">#include &quot;misc/include/util.h&quot;</span></div>
<div class="line"><span class="preprocessor">#include &quot;layers/include/layers_fwd.h&quot;</span></div>
<div class="line"><span class="preprocessor">#include &quot;layers/include/layers_bwd_data.h&quot;</span></div>
<div class="line"><span class="preprocessor">#include &quot;layers/include/layers_bwd_weights.h&quot;</span></div>
<div class="line"><span class="preprocessor">#include &quot;layers/include/losses.h&quot;</span></div>
<div class="line"><span class="preprocessor">#include &quot;layers/include/weights_update.h&quot;</span></div>
<div class="line"><span class="preprocessor">#include &quot;layers/include/primitive_wrappers.h&quot;</span></div>
<div class="line"><span class="preprocessor">#include &quot;misc/include/data_loader.h&quot;</span></div>
<div class="line"><span class="preprocessor">#include &quot;misc/include/json.hpp&quot;</span></div>
<div class="line"> </div>
<div class="line"><span class="keyword">using namespace </span>dnnl;</div>
<div class="line"> </div>
<div class="line"><span class="keywordtype">void</span> simple_net(engine::kind engine_kind, <span class="keywordtype">int</span> argc, <span class="keywordtype">char</span>** argv)</div>
<div class="line">{</div>
<div class="line">        <span class="comment">// Check if configuration file exists</span></div>
<div class="line"> </div>
<div class="line">        nlohmann::json config_file;</div>
<div class="line"> </div>
<div class="line">        <span class="keywordflow">if</span> (argc != 3){</div>
<div class="line">                std::cout &lt;&lt; <span class="stringliteral">&quot;No configuration file specified\n&quot;</span>;</div>
<div class="line">                exit(1);</div>
<div class="line">        }</div>
<div class="line"> </div>
<div class="line">        <span class="comment">// Read JSON configuration</span></div>
<div class="line">        std::ifstream config_file_stream(argv[2]);</div>
<div class="line">        <span class="keywordflow">if</span> (config_file_stream.is_open())</div>
<div class="line">        {</div>
<div class="line">                config_file_stream &gt;&gt; config_file;</div>
<div class="line">                config_file_stream.close();</div>
<div class="line">        }</div>
<div class="line">        <span class="keywordflow">else</span></div>
<div class="line">                std::cout &lt;&lt; <span class="stringliteral">&quot;Unable to open file&quot;</span>; </div>
<div class="line"> </div>
<div class="line">        <span class="comment">// RNG for ALL purposes</span></div>
<div class="line">        std::default_random_engine generator;</div>
<div class="line"> </div>
<div class="line">        <span class="keyword">auto</span> eng = engine(engine_kind, 0);</div>
<div class="line">        stream s(eng);</div>
<div class="line"> </div>
<div class="line">        <span class="comment">// MNIST dataset (binary classification, only images corresponding to 0 and 1 were kept)</span></div>
<div class="line">        <span class="comment">//unsigned long samples = 245057;</span></div>
<div class="line">        <span class="keyword">const</span> <span class="keywordtype">long</span> samples = config_file[<span class="stringliteral">&quot;samples&quot;</span>];</div>
<div class="line">        <span class="keyword">const</span> <span class="keywordtype">long</span> batch = config_file[<span class="stringliteral">&quot;minibatch_size&quot;</span>];</div>
<div class="line">        <span class="comment">// Load dataset</span></div>
<div class="line">        <span class="keyword">auto</span> dataset_path = config_file[<span class="stringliteral">&quot;dataset_path&quot;</span>];</div>
<div class="line">        <span class="keyword">auto</span> labels_path = config_file[<span class="stringliteral">&quot;labels_path&quot;</span>];</div>
<div class="line"> </div>
<div class="line">        std::vector&lt;long&gt; dataset_shape = {samples, 28, 28};      <span class="comment">//MNIST dataset</span></div>
<div class="line"> </div>
<div class="line">        <span class="comment">// Data loader </span></div>
<div class="line"> </div>
<div class="line">        <a class="code" href="classDataLoader.html">DataLoader</a> mnist_data(dataset_path, labels_path, samples, batch, dataset_shape, eng);</div>
<div class="line"> </div>
<div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;Dataloader instantiated\n&quot;</span>;</div>
<div class="line"> </div>
<div class="line">        <span class="keyword">using</span> tag = memory::format_tag;</div>
<div class="line">        <span class="keyword">using</span> dt = memory::data_type;</div>
<div class="line"> </div>
<div class="line">        <span class="comment">// Vector of primitives and their execute arguments</span></div>
<div class="line">        std::vector&lt;primitive&gt; net_fwd, net_bwd_data, net_bwd_weights, net_sgd;</div>
<div class="line">        std::vector&lt;std::unordered_map&lt;int, memory&gt;&gt; net_fwd_args, net_bwd_data_args, net_bwd_weights_args, net_sgd_args;</div>
<div class="line"> </div>
<div class="line">        <span class="keyword">const</span> <span class="keywordtype">int</span> patch_size = dataset_shape[1];</div>
<div class="line">        <span class="keyword">const</span> <span class="keywordtype">int</span> stride = 1;</div>
<div class="line">        <span class="keyword">const</span> <span class="keywordtype">int</span> kernel_size = 5;</div>
<div class="line">        <span class="keyword">const</span> <span class="keywordtype">int</span> n_kernels = 24;</div>
<div class="line">        <span class="keyword">const</span> <span class="keywordtype">float</span> learning_rate = config_file[<span class="stringliteral">&quot;learning_rate&quot;</span>];</div>
<div class="line"> </div>
<div class="line">        <span class="comment">// Compute the padding to preserve the same dimension in input and output</span></div>
<div class="line">        <span class="comment">// const int padding = (shape[1] - 1) * stride - shape[1] + kernel_size;</span></div>
<div class="line">        <span class="comment">// padding /= 2;</span></div>
<div class="line">        <span class="keywordtype">int</span> padding = kernel_size - 1;</div>
<div class="line">        padding /= 1;</div>
<div class="line"> </div>
<div class="line">        <span class="comment">// Declare clipping parameters</span></div>
<div class="line">        <span class="keywordtype">float</span> clip_upper = config_file[<span class="stringliteral">&quot;clip_upper&quot;</span>];</div>
<div class="line">        <span class="keywordtype">float</span> clip_lower = config_file[<span class="stringliteral">&quot;clip_lower&quot;</span>];</div>
<div class="line"> </div>
<div class="line">        <span class="comment">// Initialize input and write first batch</span></div>
<div class="line">        memory::dims input_dim = {batch, 1, patch_size, patch_size};</div>
<div class="line">        <span class="keyword">auto</span> input_memory = memory({{input_dim}, dt::f32, tag::nchw}, eng);</div>
<div class="line"> </div>
<div class="line">        memory::dims labels_dim = {batch, 1};</div>
<div class="line">        <span class="keyword">auto</span> labels_memory = memory({{labels_dim}, dt::f32, tag::nc}, eng);</div>
<div class="line"> </div>
<div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;Writing first batch to memory\n&quot;</span>;</div>
<div class="line">        mnist_data.write_to_memory(input_memory, labels_memory);</div>
<div class="line"> </div>
<div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;Loaded first batch \n&quot;</span>;</div>
<div class="line"> </div>
<div class="line">        <span class="comment">// Convolutional layer 1</span></div>
<div class="line">        <a class="code" href="classConv2D.html">Conv2D</a> conv1(batch, patch_size, n_kernels, kernel_size, stride, padding, 1, </div>
<div class="line">                           input_memory, net_fwd, net_fwd_args, eng);</div>
<div class="line"> </div>
<div class="line">        <a class="code" href="classEltwise.html">Eltwise</a> relu0(dnnl::algorithm::eltwise_relu, 0.f, 0.f, conv1.arg_dst,</div>
<div class="line">                            net_fwd, net_fwd_args, eng);</div>
<div class="line"> </div>
<div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;I created the first convolutional layer!\n&quot;</span>;</div>
<div class="line"> </div>
<div class="line">        <span class="comment">// Max pooling</span></div>
<div class="line">        <span class="keywordtype">int</span> pool_stride = 1;</div>
<div class="line">        <span class="keywordtype">int</span> pool_kernel = 2;</div>
<div class="line">        <a class="code" href="classMaxPool2D.html">MaxPool2D</a> maxpool1(pool_kernel, pool_stride, relu0.arg_dst, net_fwd, net_fwd_args, eng);</div>
<div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;I created the maxpooling layer!\n&quot;</span>;</div>
<div class="line"> </div>
<div class="line">        <span class="comment">// Convolutional layer 2</span></div>
<div class="line">        <span class="keywordtype">int</span> n_kernels2 = 64;</div>
<div class="line">        <a class="code" href="classConv2D.html">Conv2D</a> conv2(batch, maxpool1.arg_dst.get_desc().dims()[2], n_kernels2, kernel_size, stride, padding, 1, </div>
<div class="line">                           maxpool1.arg_dst, net_fwd, net_fwd_args, eng);</div>
<div class="line"> </div>
<div class="line">        <a class="code" href="classEltwise.html">Eltwise</a> relu1(dnnl::algorithm::eltwise_relu, 0.f, 0.f, conv2.arg_dst,</div>
<div class="line">                            net_fwd, net_fwd_args, eng);</div>
<div class="line"> </div>
<div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;I created the first convolutional layer!\n&quot;</span>;</div>
<div class="line"> </div>
<div class="line">        <span class="comment">// Max pooling</span></div>
<div class="line">        <a class="code" href="classMaxPool2D.html">MaxPool2D</a> maxpool2(pool_kernel, pool_stride, relu1.arg_dst, net_fwd, net_fwd_args, eng);</div>
<div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;I created the maxpooling layer!\n&quot;</span>;</div>
<div class="line"> </div>
<div class="line">        <span class="comment">// PnetCLS: Fully Connected 1</span></div>
<div class="line">        <span class="comment">// {batch, 64, patch_size, patch_size} -&gt; {batch, fc1_output_size}</span></div>
<div class="line"> </div>
<div class="line">        <span class="keywordtype">int</span> flatten_kernels = maxpool2.arg_dst.get_desc().dims()[1];</div>
<div class="line">        <span class="keywordtype">int</span> conv_o_h = maxpool2.arg_dst.get_desc().dims()[2];</div>
<div class="line">        <span class="keywordtype">int</span> conv_o_w = maxpool2.arg_dst.get_desc().dims()[3];</div>
<div class="line">        memory::dims fc1_src_dims = {batch, flatten_kernels, conv_o_h, conv_o_w};</div>
<div class="line">        <span class="keywordtype">int</span> fc1_output_size = 256;</div>
<div class="line">        <a class="code" href="classDense.html">Dense</a> fc1(fc1_output_size, maxpool2.arg_dst, net_fwd, net_fwd_args, eng);</div>
<div class="line"> </div>
<div class="line">        <a class="code" href="classEltwise.html">Eltwise</a> relu2(dnnl::algorithm::eltwise_relu, 0.f, 0.f, fc1.arg_dst,</div>
<div class="line">                            net_fwd, net_fwd_args, eng);</div>
<div class="line"> </div>
<div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;I created the first dense layer!\n&quot;</span>;</div>
<div class="line"> </div>
<div class="line">        <span class="comment">// PnetCLS: Fully Connected 2</span></div>
<div class="line">        <span class="comment">// {batch, fc1_output_size} -&gt; {batch, 1}</span></div>
<div class="line"> </div>
<div class="line">        memory::dims fc2_src_dims = {batch, fc1_output_size};</div>
<div class="line">        <span class="keywordtype">int</span> fc2_output_size = 1;</div>
<div class="line">        <a class="code" href="classDense.html">Dense</a> fc2(fc2_output_size, relu2.arg_dst, net_fwd, net_fwd_args, eng);</div>
<div class="line">                        </div>
<div class="line">        <a class="code" href="classEltwise.html">Eltwise</a> sigmoid1(dnnl::algorithm::eltwise_logistic, 0.f, 0.f, fc2.arg_dst,</div>
<div class="line">                            net_fwd, net_fwd_args, eng);</div>
<div class="line"> </div>
<div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;I created the second dense layer!\n&quot;</span>;</div>
<div class="line">        <a class="code" href="classbinaryCrossEntropyLoss.html">binaryCrossEntropyLoss</a> loss(sigmoid1.arg_dst, labels_memory, net_fwd, net_fwd_args, eng);</div>
<div class="line"> </div>
<div class="line">        <span class="comment">//-----------------------------------------------------------------------</span></div>
<div class="line">        <span class="comment">//----------------- Backpropagation Stream  (Data)-------------------------------------</span></div>
<div class="line"> </div>
<div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;Creating backward Loss&quot;</span> &lt;&lt; <span class="stringliteral">&quot;\n&quot;</span>;</div>
<div class="line">        <a class="code" href="classbinaryCrossEntropyLoss__back.html">binaryCrossEntropyLoss_back</a> loss_back(sigmoid1.arg_dst, labels_memory, net_bwd_data, net_bwd_data_args, eng);</div>
<div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;Creating the second Dense layer (back)\n&quot;</span>; </div>
<div class="line">        <a class="code" href="classEltwise__back.html">Eltwise_back</a> sigmoid1_back(dnnl::algorithm::eltwise_logistic, 0.f, 0.f, sigmoid1, </div>
<div class="line">                                         loss_back.arg_dst, net_bwd_data, net_bwd_data_args, eng);</div>
<div class="line">        <a class="code" href="classDense__back__data.html">Dense_back_data</a> fc2_back_data(sigmoid1_back.arg_diff_src, fc2, net_bwd_data, net_bwd_data_args, eng);</div>
<div class="line"> </div>
<div class="line">        <a class="code" href="classEltwise__back.html">Eltwise_back</a> relu2_back_data(dnnl::algorithm::eltwise_relu, 0.f, 0.f, relu2, </div>
<div class="line">                                         fc2_back_data.arg_diff_src, net_bwd_data, net_bwd_data_args, eng);</div>
<div class="line">        <a class="code" href="classDense__back__data.html">Dense_back_data</a> fc1_back_data(relu2_back_data.arg_diff_src, fc1, net_bwd_data, net_bwd_data_args, eng);</div>
<div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;Creating maxpool (back)\n&quot;</span>; </div>
<div class="line">        <a class="code" href="classMaxPool2D__back.html">MaxPool2D_back</a> maxpool2_back_data(pool_kernel, pool_stride, maxpool1, fc1_back_data.arg_diff_src, net_bwd_data, net_bwd_data_args, eng);</div>
<div class="line">        <a class="code" href="classEltwise__back.html">Eltwise_back</a> relu1_back_data(dnnl::algorithm::eltwise_relu, 0.f, 0.f, relu1, </div>
<div class="line">                                         maxpool2_back_data.arg_diff_src, net_bwd_data, net_bwd_data_args, eng);</div>
<div class="line">        <a class="code" href="classConv2D__back__data.html">Conv2D_back_data</a> conv2_back_data(relu1_back_data.arg_diff_src, conv2, stride, padding, 1, </div>
<div class="line">                                               net_bwd_data, net_bwd_data_args, eng);</div>
<div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;Creating maxpool (back)\n&quot;</span>; </div>
<div class="line">        <a class="code" href="classMaxPool2D__back.html">MaxPool2D_back</a> maxpool1_back_data(pool_kernel, pool_stride, maxpool1, conv2_back_data.arg_diff_src, net_bwd_data, net_bwd_data_args, eng);</div>
<div class="line">        <a class="code" href="classEltwise__back.html">Eltwise_back</a> relu0_back_data(dnnl::algorithm::eltwise_relu, 0.f, 0.f, relu0, </div>
<div class="line">                                         maxpool1_back_data.arg_diff_src, net_bwd_data, net_bwd_data_args, eng);</div>
<div class="line">        <a class="code" href="classConv2D__back__data.html">Conv2D_back_data</a> conv1_back_data(relu0_back_data.arg_diff_src, conv1, stride, padding, 1, </div>
<div class="line">                                               net_bwd_data, net_bwd_data_args, eng);</div>
<div class="line"> </div>
<div class="line">        </div>
<div class="line">        <span class="comment">//-----------------------------------------------------------------------</span></div>
<div class="line">        <span class="comment">//----------------- Backpropagation Stream  (Weights)-------------------------------------</span></div>
<div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;Creating the second Dense layer (back weights)\n&quot;</span>; </div>
<div class="line">        <a class="code" href="classDense__back__weights.html">Dense_back_weights</a> fc2_back_weights(sigmoid1_back.arg_diff_src, fc2, net_bwd_weights, net_bwd_weights_args, eng);</div>
<div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;Creating the first Dense layer (back weights)\n&quot;</span>; </div>
<div class="line">        <a class="code" href="classDense__back__weights.html">Dense_back_weights</a> fc1_back_weights(relu2_back_data.arg_diff_src, fc1, net_bwd_weights, net_bwd_weights_args, eng);</div>
<div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;Creating the second convolutional layer (back weights)\n&quot;</span>; </div>
<div class="line">        <a class="code" href="classConv2D__back__weights.html">Conv2D_back_weights</a> conv2_back_weights(relu1_back_data.arg_diff_src , conv2, stride, padding, 1,</div>
<div class="line">                                  net_bwd_weights, net_bwd_weights_args, eng);</div>
<div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;Creating the first convolutional layer (back weights)\n&quot;</span>; </div>
<div class="line">        <a class="code" href="classConv2D__back__weights.html">Conv2D_back_weights</a> conv1_back_weights(relu0_back_data.arg_diff_src , conv1, stride, padding, 1,</div>
<div class="line">                                  net_bwd_weights, net_bwd_weights_args, eng);</div>
<div class="line"> </div>
<div class="line">        <span class="comment">//-----------------------------------------------------------------------</span></div>
<div class="line">        <span class="comment">//----------------- Weights update -------------------------------------</span></div>
<div class="line"> </div>
<div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;Weight update conv1\n&quot;</span>;</div>
<div class="line">        updateWeights_SGD(conv1.arg_weights, </div>
<div class="line">                   conv1_back_weights.arg_diff_weights, </div>
<div class="line">                   learning_rate, net_sgd, net_sgd_args, eng);</div>
<div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;Weight update conv1\n&quot;</span>;</div>
<div class="line">        updateWeights_SGD(conv2.arg_weights, </div>
<div class="line">                   conv2_back_weights.arg_diff_weights, </div>
<div class="line">                   learning_rate, net_sgd, net_sgd_args, eng);</div>
<div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;Weight update FC1\n&quot;</span>;</div>
<div class="line">        updateWeights_SGD(fc1.arg_weights, </div>
<div class="line">                   fc1_back_weights.arg_diff_weights,</div>
<div class="line">                   learning_rate, net_sgd, net_sgd_args, eng);</div>
<div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;Weight update FC2\n&quot;</span>;</div>
<div class="line">        updateWeights_SGD(fc2.arg_weights, </div>
<div class="line">                   fc2_back_weights.arg_diff_weights,</div>
<div class="line">                   learning_rate, net_sgd, net_sgd_args, eng);</div>
<div class="line"> </div>
<div class="line">        <span class="comment">//-----------------------------------------------------------------------</span></div>
<div class="line">        <span class="comment">//----------------- Bias update -------------------------------------</span></div>
<div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;Bias update conv1\n&quot;</span>;</div>
<div class="line">        updateWeights_SGD(conv1.arg_bias, </div>
<div class="line">                  conv1_back_weights.arg_diff_bias,</div>
<div class="line">                   learning_rate, net_sgd, net_sgd_args, eng);</div>
<div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;Bias update conv1\n&quot;</span>;</div>
<div class="line">        updateWeights_SGD(conv2.arg_bias, </div>
<div class="line">                  conv2_back_weights.arg_diff_bias,</div>
<div class="line">                   learning_rate, net_sgd, net_sgd_args, eng);</div>
<div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;Bias update FC1\n&quot;</span>;</div>
<div class="line">        updateWeights_SGD(fc1.arg_bias, </div>
<div class="line">                   fc1_back_weights.arg_diff_bias,</div>
<div class="line">                   learning_rate, net_sgd, net_sgd_args, eng);</div>
<div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;Bias update FC2\n&quot;</span>;</div>
<div class="line">        updateWeights_SGD(fc2.arg_bias, </div>
<div class="line">                   fc2_back_weights.arg_diff_bias,</div>
<div class="line">                   learning_rate, net_sgd, net_sgd_args, eng);</div>
<div class="line"> </div>
<div class="line">        <span class="comment">// didn&#39;t we forget anything?</span></div>
<div class="line">        assert(net_fwd.size() == net_fwd_args.size() &amp;&amp; <span class="stringliteral">&quot;something is missing&quot;</span>);</div>
<div class="line">        assert(net_bwd_data.size() == net_bwd_data_args.size() &amp;&amp; <span class="stringliteral">&quot;something is missing&quot;</span>);</div>
<div class="line">        assert(net_bwd_weights.size() == net_bwd_weights_args.size() &amp;&amp; <span class="stringliteral">&quot;something is missing&quot;</span>);</div>
<div class="line"> </div>
<div class="line">        <span class="keywordtype">int</span> max_iter = config_file[<span class="stringliteral">&quot;iterations&quot;</span>]; <span class="comment">// number of iterations for training</span></div>
<div class="line">        <span class="keywordtype">int</span> n_iter = 0;</div>
<div class="line">        <span class="keywordtype">int</span> step = config_file[<span class="stringliteral">&quot;step&quot;</span>];</div>
<div class="line"> </div>
<div class="line">        <span class="comment">// Prepare memory that will host loss</span></div>
<div class="line">        std::vector&lt;float&gt; curr_loss_diff(batch);</div>
<div class="line">        <span class="keywordtype">float</span> curr_loss;</div>
<div class="line">        std::vector&lt;float&gt; loss_history((<span class="keywordtype">int</span>)max_iter/step);</div>
<div class="line">        </div>
<div class="line">        <span class="comment">//unsigned long batch_size = batch;</span></div>
<div class="line">        <span class="keywordtype">unsigned</span> <span class="keywordtype">long</span> batch_size = max_iter/step;</div>
<div class="line">        <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">long</span> loss_dim [] = {batch_size};</div>
<div class="line"> </div>
<div class="line">        <span class="comment">//s.wait();</span></div>
<div class="line">        <span class="comment">//print_vector2(curr_loss);</span></div>
<div class="line"> </div>
<div class="line">        <span class="comment">// execute</span></div>
<div class="line">        <span class="keywordflow">while</span> (n_iter &lt; max_iter)</div>
<div class="line">        {</div>
<div class="line">                <span class="comment">// forward</span></div>
<div class="line">                std::cout &lt;&lt; <span class="stringliteral">&quot;Iteration # &quot;</span> &lt;&lt; n_iter &lt;&lt; <span class="stringliteral">&quot;\n&quot;</span>;</div>
<div class="line"> </div>
<div class="line">                std::cout &lt;&lt; <span class="stringliteral">&quot;Forward pass\n&quot;</span>;</div>
<div class="line"> </div>
<div class="line">                <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; net_fwd.size(); ++i)</div>
<div class="line">                        net_fwd.at(i).execute(s, net_fwd_args.at(i));</div>
<div class="line"> </div>
<div class="line">                <span class="comment">// Compute the gradients with respect to the outputs</span></div>
<div class="line"> </div>
<div class="line">                std::cout &lt;&lt; <span class="stringliteral">&quot;Backward data pass\n&quot;</span>;</div>
<div class="line">                <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; net_bwd_data.size(); ++i)</div>
<div class="line">                        net_bwd_data.at(i).execute(s, net_bwd_data_args.at(i));</div>
<div class="line"> </div>
<div class="line">                <span class="comment">// Use the previous gradients to compute gradients with respect to the weights</span></div>
<div class="line"> </div>
<div class="line">                std::cout &lt;&lt; <span class="stringliteral">&quot;Backward weights pass\n&quot;</span>;</div>
<div class="line">                <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; net_bwd_weights.size(); ++i)</div>
<div class="line">                        net_bwd_weights.at(i).execute(s, net_bwd_weights_args.at(i));</div>
<div class="line"> </div>
<div class="line"> </div>
<div class="line">                <span class="comment">// Time to update the weights!</span></div>
<div class="line">                std::cout &lt;&lt; <span class="stringliteral">&quot;Weights update\n&quot;</span>;</div>
<div class="line">                <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; net_sgd.size(); ++i)</div>
<div class="line">                        net_sgd.at(i).execute(s, net_sgd_args.at(i));</div>
<div class="line"> </div>
<div class="line"> </div>
<div class="line">                </div>
<div class="line"> </div>
<div class="line">                <span class="keywordflow">if</span> (n_iter % step == 0){  </div>
<div class="line">                        s.wait();</div>
<div class="line">                        read_from_dnnl_memory(&amp;curr_loss, loss.arg_dst);                        </div>
<div class="line">                        loss_history[(int)n_iter/step] = curr_loss;</div>
<div class="line">                }</div>
<div class="line"> </div>
<div class="line">                <span class="comment">// Change data</span></div>
<div class="line">                mnist_data.write_to_memory(input_memory, labels_memory);</div>
<div class="line"> </div>
<div class="line">                n_iter++;</div>
<div class="line">        }</div>
<div class="line"> </div>
<div class="line">        <span class="comment">//std::string loss_filename = &quot;./data/losses/iteration_&quot; + std::to_string(n_iter) + &quot;.npy&quot;;  </span></div>
<div class="line">        std::string loss_filename = config_file[<span class="stringliteral">&quot;loss_filename&quot;</span>];  </div>
<div class="line">        npy::SaveArrayAsNumpy(loss_filename, <span class="keyword">false</span>, 1, loss_dim, loss_history);</div>
<div class="line"> </div>
<div class="line">        s.wait();</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line"><span class="keywordtype">int</span> main(<span class="keywordtype">int</span> argc, <span class="keywordtype">char</span> **argv)</div>
<div class="line">{</div>
<div class="line">        <span class="comment">// Config file</span></div>
<div class="line">        <span class="keywordtype">int</span> extra_args = 1;</div>
<div class="line">        <span class="keywordflow">return</span> handle_example_errors(simple_net, parse_engine_kind(argc, argv, extra_args), argc, argv);</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="ttc" id="aclassConv2D__back__data_html"><div class="ttname"><a href="classConv2D__back__data.html">Conv2D_back_data</a></div><div class="ttdoc">Backward Data convolution.</div><div class="ttdef"><b>Definition:</b> layers_bwd_data.h:18</div></div>
<div class="ttc" id="aclassConv2D__back__weights_html"><div class="ttname"><a href="classConv2D__back__weights.html">Conv2D_back_weights</a></div><div class="ttdoc">Primitive which provides backward weights pass for Conv2D.</div><div class="ttdef"><b>Definition:</b> layers_bwd_weights.h:19</div></div>
<div class="ttc" id="aclassConv2D_html"><div class="ttname"><a href="classConv2D.html">Conv2D</a></div><div class="ttdoc">Conv2D allows to create a forward convolution primitive.</div><div class="ttdef"><b>Definition:</b> layers_fwd.h:50</div></div>
<div class="ttc" id="aclassDataLoader_html"><div class="ttname"><a href="classDataLoader.html">DataLoader</a></div><div class="ttdoc">DataLoader allows to create a dataloader object to implement minibatch stochastic gradient descent.</div><div class="ttdef"><b>Definition:</b> data_loader.h:18</div></div>
<div class="ttc" id="aclassDense__back__data_html"><div class="ttname"><a href="classDense__back__data.html">Dense_back_data</a></div><div class="ttdoc">Dense layer backward data primitive.</div><div class="ttdef"><b>Definition:</b> layers_bwd_data.h:109</div></div>
<div class="ttc" id="aclassDense__back__weights_html"><div class="ttname"><a href="classDense__back__weights.html">Dense_back_weights</a></div><div class="ttdoc">Primitive which provides backward weights pass for the Dense.</div><div class="ttdef"><b>Definition:</b> layers_bwd_weights.h:50</div></div>
<div class="ttc" id="aclassDense_html"><div class="ttname"><a href="classDense.html">Dense</a></div><div class="ttdoc">Dense allows to create a fully connected layer forward primitive.</div><div class="ttdef"><b>Definition:</b> layers_fwd.h:22</div></div>
<div class="ttc" id="aclassEltwise__back_html"><div class="ttname"><a href="classEltwise__back.html">Eltwise_back</a></div><div class="ttdoc">Eltwise backward primitive.</div><div class="ttdef"><b>Definition:</b> layers_bwd_data.h:77</div></div>
<div class="ttc" id="aclassEltwise_html"><div class="ttname"><a href="classEltwise.html">Eltwise</a></div><div class="ttdoc">Primitive which provides element-wise operations.</div><div class="ttdef"><b>Definition:</b> primitive_wrappers.h:41</div></div>
<div class="ttc" id="aclassMaxPool2D__back_html"><div class="ttname"><a href="classMaxPool2D__back.html">MaxPool2D_back</a></div><div class="ttdoc">Backward Data operation for 2D Max Pooling.</div><div class="ttdef"><b>Definition:</b> layers_bwd_data.h:50</div></div>
<div class="ttc" id="aclassMaxPool2D_html"><div class="ttname"><a href="classMaxPool2D.html">MaxPool2D</a></div><div class="ttdoc">Primitive which provides max pooling.</div><div class="ttdef"><b>Definition:</b> layers_fwd.h:88</div></div>
<div class="ttc" id="aclassbinaryCrossEntropyLoss__back_html"><div class="ttname"><a href="classbinaryCrossEntropyLoss__back.html">binaryCrossEntropyLoss_back</a></div><div class="ttdoc">Gradient of binary cross entropy loss.</div><div class="ttdef"><b>Definition:</b> losses.h:92</div></div>
<div class="ttc" id="aclassbinaryCrossEntropyLoss_html"><div class="ttname"><a href="classbinaryCrossEntropyLoss.html">binaryCrossEntropyLoss</a></div><div class="ttdoc">Binary Cross Entropy Loss class.</div><div class="ttdef"><b>Definition:</b> losses.h:67</div></div>
</div><!-- fragment --> </div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1 </li>
  </ul>
</div>
</body>
</html>
